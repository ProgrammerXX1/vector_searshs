# app/core/weaviate_client.py
from __future__ import annotations

import os
import atexit
import logging
from typing import Optional

import numpy as np
import uuid as _uuid
from datetime import datetime, timedelta, timezone
from random import Random

from weaviate import WeaviateClient
from weaviate.connect import ConnectionParams
from weaviate.classes.init import AdditionalConfig, Timeout
from weaviate.classes.config import Configure, Property, DataType, VectorDistances
from weaviate.classes.query import Filter
from weaviate.classes.data import DataObject

logger = logging.getLogger(__name__)

DOC_COLLECTION = "Document"
_CLIENT: Optional[WeaviateClient] = None


def _str_to_bool(v: str) -> bool:
    return str(v).lower() in ("1", "true", "yes", "y")


def get_client() -> WeaviateClient:
    global _CLIENT
    if _CLIENT is None:
        _CLIENT = WeaviateClient(
            connection_params=ConnectionParams.from_params(
                http_host=os.getenv("WEAVIATE_HTTP_HOST", "localhost"),
                http_port=int(os.getenv("WEAVIATE_HTTP_PORT", 8080)),
                http_secure=_str_to_bool(os.getenv("WEAVIATE_HTTP_SECURE", "false")),
                grpc_host=os.getenv("WEAVIATE_GRPC_HOST", "localhost"),
                grpc_port=int(os.getenv("WEAVIATE_GRPC_PORT", 50051)),
                grpc_secure=_str_to_bool(os.getenv("WEAVIATE_GRPC_SECURE", "false")),
            ),
            additional_config=AdditionalConfig(grpc=True, timeout=Timeout(init=10)),
            skip_init_checks=True,
        )
    return _CLIENT


def connect() -> None:
    c = get_client()
    if not c.is_connected():
        c.connect()


def close_client() -> None:
    global _CLIENT
    if _CLIENT is None:
        return
    try:
        if _CLIENT.is_connected():
            _CLIENT.close()
    except Exception:
        pass


atexit.register(close_client)


def ensure_schema() -> None:
    """–°–æ–∑–¥–∞—Ç—å (–∏–ª–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç—å) –∫–æ–ª–ª–µ–∫—Ü–∏—é –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (cosine/HNSW)."""
    connect()
    client = get_client()

    exists = client.collections.exists(DOC_COLLECTION)

    props = [
        Property(name="text", data_type=DataType.TEXT, description="–¢–µ–∫—Å—Ç —á–∞–Ω–∫–∞"),
        Property(name="case_id", data_type=DataType.INT),
        Property(name="document_id", data_type=DataType.INT),
        Property(name="chunk_idx", data_type=DataType.INT),
        Property(name="source_page", data_type=DataType.INT),
        Property(name="created_at", data_type=DataType.DATE),
        Property(name="lang", data_type=DataType.TEXT),
        Property(name="doc_type", data_type=DataType.TEXT),
    ]

    if not exists:
        client.collections.create(
            name=DOC_COLLECTION,
            properties=props,
            vectorizer_config=Configure.Vectorizer.none(),
            vector_index_config=Configure.VectorIndex.hnsw(
                distance_metric=VectorDistances.COSINE
            ),
        )
        logger.info("‚úÖ Created collection %s", DOC_COLLECTION)
    else:
        col = client.collections.get(DOC_COLLECTION)
        existing = {p.name for p in col.config.get().properties}
        for p in props:
            if p.name not in existing:
                col.config.add_property(p)
        logger.info("‚ÑπÔ∏è Collection %s exists; properties verified", DOC_COLLECTION)


def drop_collection() -> bool:
    connect()
    client = get_client()
    try:
        if client.collections.exists(DOC_COLLECTION):
            client.collections.delete(DOC_COLLECTION)
            logger.info("üóëÔ∏è Dropped collection %s", DOC_COLLECTION)
        return True
    except Exception as e:
        logger.error("drop_collection error: %s", e)
        return False


def insert_many(items: list[dict]) -> list[str | None]:
    """
    items: [{"uuid": str|None, "vector": list[float], "properties": {...}}]
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ UUID (—Å—Ç—Ä–æ–∫–∏), –∫–æ—Ç–æ—Ä—ã–µ –º—ã —Å–∞–º–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º/–ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º.
    """
    connect()
    col = get_client().collections.get(DOC_COLLECTION)

    objs: list[DataObject] = []
    uuids: list[str] = []

    for it in items:
        uid = it.get("uuid") or str(_uuid.uuid4())
        uuids.append(uid)
        props = it["properties"]
        vec = it["vector"]
        objs.append(DataObject(uuid=uid, properties=props, vector=vec))

    try:
        col.data.insert_many(objs)
        return uuids
    except Exception as e:
        logger.error("insert_many failed: %s. Fallback to per-item.", e)
        out: list[str | None] = []
        for o in objs:
            try:
                col.data.insert(uuid=o.uuid, properties=o.properties, vector=o.vector)
                out.append(o.uuid)
            except Exception as ee:
                logger.error("insert failed for %s: %s", o.uuid, ee)
                out.append(None)
        return out

def _normalize_vector(vec) -> list[float] | None:
    """–ü—Ä–∏–≤–µ—Å—Ç–∏ –≤–µ–∫—Ç–æ—Ä –∫ list[float], –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –º—É–ª—å—Ç–∏–≤–µ–∫—Ç–æ—Ä–æ–≤ Weaviate {'default': [...]} –∏ –¥—Ä."""
    if vec is None:
        return None

    # –£–∂–µ –º–∞—Å—Å–∏–≤/—Å–ø–∏—Å–æ–∫
    if isinstance(vec, (list, tuple)):
        try:
            return [float(x) for x in vec]
        except Exception:
            return None

    if isinstance(vec, np.ndarray):
        return [float(x) for x in vec.tolist()]

    if isinstance(vec, dict):
        # –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –∫–ª—é—á–∏ —É Weaviate/multivectors
        preferred_keys = ("default", "vector", "vectors", "data", "values", "value", "embedding")
        for key in preferred_keys:
            v = vec.get(key)
            if isinstance(v, np.ndarray):
                return [float(x) for x in v.tolist()]
            if isinstance(v, (list, tuple)):
                try:
                    return [float(x) for x in v]
                except Exception:
                    pass

        # –ï—Å–ª–∏ —ç—Ç–æ –º–∞–ø–∞ name -> list[float], –±–µ—Ä—ë–º –ø–µ—Ä–≤—ã–π —Å–ø–∏—Å–æ–∫
        for _, v in vec.items():
            if isinstance(v, np.ndarray):
                return [float(x) for x in v.tolist()]
            if isinstance(v, (list, tuple)) and (len(v) == 0 or isinstance(v[0], (int, float))):
                try:
                    return [float(x) for x in v]
                except Exception:
                    pass

        # –ï—Å–ª–∏ —ç—Ç–æ –∏–Ω–¥–µ–∫—Å->–∑–Ω–∞—á–µ–Ω–∏–µ (—Ä–µ–¥–∫–æ)
        try:
            keys = sorted(vec.keys(), key=lambda k: int(k) if str(k).isdigit() else str(k))
            return [float(vec[k]) for k in keys]
        except Exception:
            return None

    return None


def _build_filters(
    *, case_id: int | None, document_id: int | None, lang: str | None, doc_types: list[str] | None = None
):
    w = None
    if case_id is not None:
        w = Filter.by_property("case_id").equal(case_id)
    if document_id is not None:
        f2 = Filter.by_property("document_id").equal(document_id)
        w = f2 if w is None else (w & f2)
    if lang is not None:
        f3 = Filter.by_property("lang").equal(lang)
        w = f3 if w is None else (w & f3)
    if doc_types:
        ors = None
        for t in doc_types:
            f = Filter.by_property("doc_type").equal(t)
            ors = f if ors is None else (ors | f)
        w = ors if w is None else (w & ors)
    return w


def near_vector_search(
    vector: list[float],
    limit: int = 10,
    case_id: int | None = None,
    document_id: int | None = None,
    lang: str | None = None,
):
    """–ü—Ä–æ—Å—Ç–æ–π dense-–ø–æ–∏—Å–∫ (ANN) —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç [{id, score, distance, properties}]."""
    connect()
    col = get_client().collections.get(DOC_COLLECTION)

    w = _build_filters(case_id=case_id, document_id=document_id, lang=lang)

    result = col.query.near_vector(
        near_vector=vector,
        limit=limit,
        filters=w,
        return_metadata=["distance"],
        include_vector=False,
    )

    hits = []
    for o in result.objects:
        uid = str(o.uuid)
        dist = float(o.metadata.distance) if o.metadata.distance is not None else float("nan")
        score = (1.0 - dist) if dist == dist else 0.0
        hits.append(
            {
                "id": uid,
                "score": score,
                "distance": 0.0 if dist != dist else dist,
                "properties": o.properties or {},
            }
        )
    return hits


def bm25_search(
    query_text: str,
    limit: int = 10,
    *,
    case_id: int | None = None,
    document_id: int | None = None,
    lang: str | None = None,
    doc_types: list[str] | None = None,
):
    """BM25 –ø–æ –ø–æ–ª—é text (–∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å Weaviate)."""
    connect()
    col = get_client().collections.get(DOC_COLLECTION)
    w = _build_filters(case_id=case_id, document_id=document_id, lang=lang, doc_types=doc_types)

    res = col.query.bm25(
        query=query_text,
        query_properties=["text"],
        limit=limit,
        filters=w,
        return_metadata=["score"],
        include_vector=False,
    )

    hits = []
    for o in res.objects:
        uid = str(o.uuid)
        score = float(o.metadata.score or 0.0)
        hits.append(
            {
                "id": uid,
                "score": score,  # BM25 score (–±–æ–ª—å—à–µ = –ª—É—á—à–µ)
                "distance": 0.0,
                "properties": o.properties or {},
            }
        )
    return hits


def near_vector_raw(
    vector: list[float],
    limit: int = 100,
    *,
    case_id: int | None = None,
    document_id: int | None = None,
    lang: str | None = None,
    include_vec: bool = True,
):
    """Dense-–ø–æ–∏—Å–∫ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –≤–µ—Ä–Ω—É—Ç—å —Å–∞–º–∏ –≤–µ–∫—Ç–æ—Ä—ã (–¥–ª—è MMR)."""
    connect()
    col = get_client().collections.get(DOC_COLLECTION)
    w = _build_filters(case_id=case_id, document_id=document_id, lang=lang)

    res = col.query.near_vector(
        near_vector=vector,
        limit=limit,
        filters=w,
        return_metadata=["distance"],
        include_vector=include_vec,
    )

    items = []
    for o in res.objects:
        uid = str(o.uuid)
        dist = float(o.metadata.distance) if o.metadata.distance is not None else float("nan")
        sim = (1.0 - dist) if dist == dist else 0.0
        vec = getattr(o, "vector", None)
        vec = _normalize_vector(vec)   # ‚úÖ –ø—Ä–∏–≤–µ–ª–∏ –∫ list[float] –∏–ª–∏ None
        items.append(
            {
                "id": uid,
                "score": sim,
                "distance": 0.0 if dist != dist else dist,
                "vector": vec,
                "properties": o.properties or {},
            }
        )
    return items


def _rrf_merge(dense: list[dict], sparse: list[dict], limit: int, c: int = 60):
    """Reciprocal Rank Fusion: –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–∞–Ω–≥–æ–≤ dense –∏ sparse."""
    ranks: dict[str, list[int]] = {}
    all_items: dict[str, dict] = {}

    for lst in (dense, sparse):
        for i, it in enumerate(lst):
            _id = it["id"]
            ranks.setdefault(_id, []).append(i + 1)
            all_items[_id] = it

    fused = []
    for _id, rks in ranks.items():
        score = sum(1.0 / (c + r) for r in rks)  # –±–æ–ª—å—à–µ = –ª—É—á—à–µ
        fused.append((score, all_items[_id]))
    fused.sort(key=lambda x: x[0], reverse=True)
    return [it for _, it in fused[:limit]]


def hybrid_rrf_search(
    *,
    vector: list[float],
    query_text: str,
    k_dense: int = 100,
    k_bm25: int = 200,
    limit: int = 10,
    case_id: int | None = None,
    document_id: int | None = None,
    lang: str | None = None,
    doc_types: list[str] | None = None,
):
    """Hybrid: RRF(dense, bm25)."""
    dense = near_vector_raw(
        vector, limit=k_dense, case_id=case_id, document_id=document_id, lang=lang, include_vec=False
    )
    sparse = bm25_search(
        query_text, limit=k_bm25, case_id=case_id, document_id=document_id, lang=lang, doc_types=doc_types
    )
    merged = _rrf_merge(dense, sparse, limit=limit, c=60)
    hits = []
    for it in merged:
        hits.append(
            {
                "id": it["id"],
                "score": it.get("score", 0.0),
                "distance": it.get("distance", 0.0),
                "properties": it.get("properties", {}),
            }
        )
    return hits


def mmr_search(
    *,
    vector: list[float],
    k_candidates: int = 100,
    top_n: int = 20,
    lambda_mult: float = 0.5,
    case_id: int | None = None,
    document_id: int | None = None,
    lang: str | None = None,
):
    """MMR-–¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ–≤–µ—Ä—Ö dense-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã)."""
    # –∫–∞–Ω–¥–∏–¥–∞—Ç—ã (–ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –≤–µ–∫—Ç–æ—Ä—ã)
    cands = near_vector_raw(
        vector, limit=k_candidates, case_id=case_id, document_id=document_id, lang=lang, include_vec=True
    )

    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
    target_dim = len(vector)
    valid = []
    for it in cands:
        v = _normalize_vector(it.get("vector"))
        if v is None or len(v) != target_dim:
            continue
        valid.append({"item": it, "vec": np.array(v, dtype=np.float32)})

    if not valid:
        basic = near_vector_search(vector=vector, limit=top_n, case_id=case_id, document_id=document_id, lang=lang)
        return []

    # –º–∞—Ç—Ä–∏—Ü–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    V = np.stack([x["vec"] for x in valid], axis=0)  # (N, d)
    V = V / (np.linalg.norm(V, axis=1, keepdims=True) + 1e-12)
    q = np.array(vector, dtype=np.float32)
    q = q / (np.linalg.norm(q) + 1e-12)

    sim_to_q = V @ q  # (N,)
    selected_idx = []

    # —Å—Ç–∞—Ä—Ç ‚Äî –ª—É—á—à–∏–π –ø–æ –∑–∞–ø—Ä–æ—Å—É
    first = int(np.argmax(sim_to_q))
    selected_idx.append(first)

    cand_idx = list(range(len(valid)))
    cand_idx.remove(first)

    while len(selected_idx) < min(top_n, len(valid)):
        rel = sim_to_q[cand_idx]  # –±–ª–∏–∑–æ—Å—Ç—å –∫ –∑–∞–ø—Ä–æ—Å—É
        # —à—Ç—Ä–∞—Ñ –∑–∞ —Å—Ö–æ–∂–µ—Å—Ç—å —Å —É–∂–µ –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏
        if selected_idx:
            div = (V[cand_idx] @ V[selected_idx].T).max(axis=1)
        else:
            div = 0.0
        score = lambda_mult * rel - (1.0 - lambda_mult) * div
        j = int(np.argmax(score))
        picked = cand_idx[j]
        selected_idx.append(picked)
        cand_idx.remove(picked)

    # —Å–æ–±—Ä–∞—Ç—å –≤—ã–¥–∞—á—É –∏–∑ valid (–∞ –Ω–µ –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö cands!)
    out = []
    for idx in selected_idx:
        it = valid[idx]["item"]
        sim = float(sim_to_q[idx])
        dist = 1.0 - sim
        out.append({
            "id": it["id"],
            "score": sim,
            "distance": dist,
            "properties": it["properties"]
        })
    return out



def near_object_search(
    *,
    object_id: str,
    limit: int = 10,
    case_id: int | None = None,
    document_id: int | None = None,
    lang: str | None = None,
):
    """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –æ–±—ä–µ–∫—Ç (nearObject)."""
    connect()
    col = get_client().collections.get(DOC_COLLECTION)
    w = _build_filters(case_id=case_id, document_id=document_id, lang=lang)

    res = col.query.near_object(
        near_object=object_id,
        limit=limit,
        filters=w,
        return_metadata=["distance"],
        include_vector=False,
    )

    hits = []
    for o in res.objects:
        uid = str(o.uuid)
        dist = float(o.metadata.distance) if o.metadata.distance is not None else float("nan")
        sim = (1.0 - dist) if dist == dist else 0.0
        hits.append({"id": uid, "score": sim, "distance": 0.0 if dist != dist else dist, "properties": o.properties or {}})
    return hits


def seed_data(count: int = 200, dim: int = 4, case_id: int = 1) -> list[str]:
    """
    –°–∏–¥–µ—Ä: 200 –æ–±—ä–µ–∫—Ç–æ–≤ –≤–æ–∫—Ä—É–≥ 4 —Ü–µ–Ω—Ç—Ä–æ–≤ (A,B,C,D) ‚Äî —É–¥–æ–±–Ω–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –ø–æ–∏—Å–∫–∏.
    A TAKORP (interrogation/statement)
    B Banking/IBAN/USDT (bank_record/transfer)
    C Contract/Legal (contract/order)
    D Web/Promo (webpage/notice)
    """
    assert dim == 4, "–î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã —Å–∏–¥–µ—Ä–∞ dim=4"
    connect()
    col = get_client().collections.get(DOC_COLLECTION)
    rnd = Random(42)

    centers = {
        "A": np.array([0.62, 0.58, 0.12, 0.09], dtype=np.float32),
        "B": np.array([0.10, 0.12, 0.70, 0.60], dtype=np.float32),
        "C": np.array([0.60, 0.12, 0.60, 0.12], dtype=np.float32),
        "D": np.array([0.12, 0.60, 0.12, 0.60], dtype=np.float32),
    }
    texts = {
        "A": [
            "–Ø –≤–ª–æ–∂–∏–ª –¥–µ–Ω—å–≥–∏ –≤ TAKORP",
            "–ü–æ—Ç–µ—Ä–ø–µ–≤—à–∏–π —Å–æ–æ–±—â–∏–ª –æ –≤–ª–æ–∂–µ–Ω–∏—è—Ö –≤ –ø–∏—Ä–∞–º–∏–¥—É TAKORP",
            "TAKORP –æ–±–µ—â–∞–ª–∞ 15% –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ",
            "–†–µ–∫–ª–∞–º–∞ –ø—Ä–æ–µ–∫—Ç–∞ TAKORP –≤ Telegram-–∫–∞–Ω–∞–ª–µ",
            "–î–æ–≥–æ–≤–æ—Ä –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π —Å TAKORP",
        ],
        "B": [
            "IBAN KZ123 —É–∫–∞–∑–∞–Ω –≤ –ø–ª–∞—Ç—ë–∂–Ω–æ–º –ø–æ—Ä—É—á–µ–Ω–∏–∏",
            "–ü–ª–∞—Ç—ë–∂ –Ω–∞ —Å—É–º–º—É —Å–≤—ã—à–µ 1 –º–ª–Ω —Ç–≥",
            "USDT –ø–µ—Ä–µ–≤–æ–¥ –Ω–∞ –∫—Ä–∏–ø—Ç–æ–∫–æ—à–µ–ª—ë–∫",
            "–û–ø–µ—Ä–∞—Ü–∏–∏ –ø–æ –∫–∞—Ä—Ç–µ ****4321 –∑–∞ –º–∞–π 2023",
            "–ë–∞–Ω–∫–æ–≤—Å–∫–∞—è –≤—ã–ø–∏—Å–∫–∞: –≤—Ö–æ–¥—è—â–∏–µ –ø–µ—Ä–µ–≤–æ–¥—ã",
        ],
        "C": [
            "–ö–æ–Ω—Ç—Ä–∞–∫—Ç –Ω–∞ –ø–æ—Å—Ç–∞–≤–∫—É –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è",
            "–î–æ–≥–æ–≤–æ—Ä –∑–∞–π–º–∞ –º–µ–∂–¥—É —Å—Ç–æ—Ä–æ–Ω–∞–º–∏",
            "–ü—Ä–∏–∫–∞–∑ –æ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏",
            "–†–∞—Å–ø–æ—Ä—è–∂–µ–Ω–∏–µ –æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–∏ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã",
            "–°–æ–≥–ª–∞—à–µ–Ω–∏–µ –æ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏",
        ],
        "D": [
            "–õ–µ–Ω–¥–∏–Ω–≥ —Å –æ–±–µ—â–∞–Ω–∏–µ–º –≤—ã—Å–æ–∫–æ–π –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏",
            "–†–µ–∫–ª–∞–º–∞ –≤ —Å–æ—Ü—Å–µ—Ç—è—Ö –∏ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–∞—Ö",
            "–ü—É–±–ª–∏—á–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –Ω–∞ —Å–∞–π—Ç–µ",
            "–û–ø–∏—Å–∞–Ω–∏–µ –±–æ–Ω—É—Å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã",
            "–û—Ç–∑—ã–≤ –Ω–∞ —Ñ–æ—Ä—É–º–µ –æ –ø—Ä–æ–µ–∫—Ç–µ",
        ],
    }
    dtypes = {"A": ["interrogation", "statement"], "B": ["bank_record", "transfer"], "C": ["contract", "order"], "D": ["webpage", "notice"]}

    batch_objs: list[DataObject] = []
    ids: list[str] = []
    now = datetime.now(timezone.utc)

    for i in range(count):
        bucket = "ABCD"[i % 4]
        center = centers[bucket]
        vec = center + np.random.normal(0.0, 0.02, size=(dim,)).astype(np.float32)

        doc_id = 1000 + i
        text = texts[bucket][i % len(texts[bucket])]
        doc_type = dtypes[bucket][i % len(dtypes[bucket])]
        created_at = (now - timedelta(days=rnd.randint(0, 365))).isoformat()

        props = {
            "text": text,
            "case_id": case_id,
            "document_id": doc_id,
            "chunk_idx": i % 5,
            "source_page": (i % 7) + 1,
            "created_at": created_at,
            "lang": "ru",
            "doc_type": doc_type,
        }
        uid = str(_uuid.uuid4())
        ids.append(uid)
        batch_objs.append(DataObject(uuid=uid, properties=props, vector=vec.tolist()))

    for s in range(0, len(batch_objs), 128):
        col.data.insert_many(batch_objs[s : s + 128])

    return ids


__all__ = [
    "get_client",
    "connect",
    "close_client",
    "ensure_schema",
    "drop_collection",
    "insert_many",
    "near_vector_search",
    "bm25_search",
    "near_vector_raw",
    "hybrid_rrf_search",
    "mmr_search",
    "near_object_search",
    "seed_data",
]
